{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Development Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "up to date, audited 1081 packages in 1s\n",
      "\n",
      "348 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "14 moderate severity vulnerabilities\n",
      "\n",
      "To address issues that do not require attention, run:\n",
      "  npm audit fix\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\n",
      "> frontend@0.1.0 dev\n",
      "> next dev\n",
      "\n",
      "\u001b[1m\u001b[38;2;173;127;168m▲ Next.js 16.1.6\u001b[39m\u001b[22m (Turbopack)\n",
      "- Local:         http://localhost:3000\n",
      "- Network:       http://10.100.1.217:3000\n",
      "- Environments: .env\n",
      "\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Starting...\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Ready in 520ms\n",
      "\u001b[37m\u001b[1m○\u001b[22m\u001b[39m Compiling / ...\n",
      " GET / \u001b[32m200\u001b[39m in 8.5s\u001b[2m (compile: 8.1s, render: 443ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1498ms\u001b[2m (compile: 1477ms, render: 21ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1499ms\u001b[2m (compile: 1479ms, render: 20ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1527ms\u001b[2m (compile: 1507ms, render: 20ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1526ms\u001b[2m (compile: 1506ms, render: 20ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1444ms\u001b[2m (compile: 1423ms, render: 20ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 1497ms\u001b[2m (compile: 1476ms, render: 20ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 6ms\u001b[2m (compile: 4ms, render: 2ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 13ms\u001b[2m (compile: 11ms, render: 2ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 10ms\u001b[2m (compile: 6ms, render: 4ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 9ms\u001b[2m (compile: 7ms, render: 2ms)\u001b[22m\n",
      " POST /api/copilotkit \u001b[33m404\u001b[39m in 8ms\u001b[2m (compile: 5ms, render: 2ms)\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd frontend && npm install && npm run dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import threading\nimport uvicorn\nfrom ag_ui_langgraph import add_langgraph_fastapi_endpoint\nfrom copilotkit import LangGraphAGUIAgent\nfrom fastapi import FastAPI\nfrom langgraph.checkpoint.memory import MemorySaver\n\napp = FastAPI()\nmemory = MemorySaver()\n\nagent = LangGraphAGUIAgent(\n    name=\"sample_agent\",\n    description=\"An example agent.\",\n    graph=None,\n)\nadd_langgraph_fastapi_endpoint(app=app, agent=agent, path=\"/\")\n\nthreading.Thread(\n    target=lambda: uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\"),\n    daemon=True,\n).start()\n\nprint(\"Server running at http://localhost:8000\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.graph import END, START, MessagesState, StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langchain_core.messages import SystemMessage\nfrom langchain_openai import ChatOpenAI\n\n\nasync def chat(state: MessagesState):\n    model = ChatOpenAI(model=\"gpt-4o-mini\")\n    system_message = SystemMessage(content=\"You are a helpful assistant.\")\n    response = await model.ainvoke([system_message, *state[\"messages\"]])\n    return {\"messages\": response}\n\n\nmemory = MemorySaver()\ngraph = StateGraph(MessagesState)\ngraph.add_node(chat)\ngraph.add_edge(START, \"chat\")\ngraph.add_edge(\"chat\", END)\n\nagent.graph = graph.compile(checkpointer=memory)\nprint(\"Agent updated!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}